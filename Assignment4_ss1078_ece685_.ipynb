{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>ECE 685D, Fall 2020 </center></h1>\n",
    "<h2><center>Problem Set 4 </center></h2>\n",
    "<h2><center> Full name: Srishti Saha (ss1078)</center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Classification with Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! mkdir data_QD\n",
    "data_dir = './data_QD/'\n",
    "files = os.listdir(data_dir)\n",
    "files = [f for f in files if 'npy' in f]\n",
    "\n",
    "# load data for specific classes\n",
    "labels = ['airplane', 'basket', 'basketball', 'bed', 'bus', \n",
    "          'calculator', 'cookie', 'eyeglasses', 'mushroom', 'pizza']\n",
    "index_to_object = {k:v for k,v in zip(range(10), labels)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    This function samples random 6000 images for train \n",
    "    and 1000 images for test from each class.\n",
    "    \"\"\"\n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "    for index, f in enumerate(files):\n",
    "        x_iter = np.load(data_dir+f, allow_pickle=True)\n",
    "        x_iter = x_iter[np.random.choice(range(x_iter.shape[0]),7000),:]\n",
    "        x_train, x_test = train_test_split(x_iter, test_size=1000)\n",
    "        X_train.append(x_train)\n",
    "        X_test.append(x_test)\n",
    "        y_train = y_train + ([index]*6000)\n",
    "        y_test = y_test + ([index]*1000)\n",
    "    \n",
    "    X_train = np.array(X_train).reshape(-1, 784)\n",
    "    X_test = np.array(X_test).reshape(-1, 784)\n",
    "    y_train, y_test = np.array(y_train), np.array(y_test)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetQD(Dataset):\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        self.features = X\n",
    "        self.label = y\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = self.features[index].astype(np.uint8).reshape((28, 28))\n",
    "        label = self.label[index]\n",
    "            \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "    \n",
    "# create transform\n",
    "transform_train = transforms.Compose(\n",
    "    [transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "transform_test = transforms.Compose(\n",
    "    [transforms.ToTensor()\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=DatasetQD(X_train,y_train,transform=transform_train)\n",
    "test_df=DatasetQD(X_test,y_test,transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "train_loader=torch.utils.data.DataLoader(train_df,batch_size=batch_size, shuffle=True)\n",
    "test_loader=torch.utils.data.DataLoader(test_df,batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier_QD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier_QD,self).__init__()\n",
    "        self.cnn_layers = nn.Sequential(nn.Conv2d(1,10,kernel_size=5,bias=True),\n",
    "                                        nn.MaxPool2d(2,stride=2),\n",
    "                                        nn.ReLU(inplace=True),\n",
    "                                        nn.Conv2d(10,20,kernel_size=5,bias=True),\n",
    "                                        nn.MaxPool2d(2,stride=2),\n",
    "                                        nn.Flatten())\n",
    "        self.dense_layers = nn.Sequential(nn.Linear(320,128),\n",
    "                                          nn.ReLU(inplace=True),\n",
    "                                          nn.Linear(128,64),\n",
    "                                          nn.ReLU(inplace=True),\n",
    "                                          nn.Linear(64,10)) \n",
    "        \n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=self.cnn_layers(x)\n",
    "        x=(self.dense_layers(x))\n",
    "        return (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_optimizer(optimizer_name, model, **kwargs):\n",
    "    if optimizer_name=='Adam':\n",
    "        optimizer = optim.Adam(model.parameters(),lr=kwargs['lr'])\n",
    "    elif optimizer_name=='SGD':\n",
    "        optimizer = optim.SGD(model.parameters(),lr=kwargs['lr'],momentum=kwargs['momentum'], weight_decay=kwargs['weight_decay'])\n",
    "    else:\n",
    "        raise ValueError('Not valid optimizer name')\n",
    "    return optimizer\n",
    "    \n",
    "def make_scheduler(scheduler_name, optimizer, **kwargs):\n",
    "    if scheduler_name=='MultiStepLR':\n",
    "        scheduler = optim.lr_scheduler.MultiStepLR(optimizer,milestones=kwargs['milestones'],gamma=kwargs['factor'])\n",
    "    else:\n",
    "        raise ValueError('Not valid scheduler name')\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, epoch):\n",
    "    \"\"\"\n",
    "    Train for 1 epoch\n",
    "    \"\"\"\n",
    "    train_loss = 0\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        target=Variable(target.long())\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    # print status update\n",
    "    print('Train(epoch:{}): Accuracy: {:.4f}%'.format(epoch, 100. * correct / len(train_loader.dataset)))\n",
    "    return (correct / len(train_loader.dataset))\n",
    "\n",
    "def test(model, test_loader, criterion, epoch):\n",
    "    \"\"\"\n",
    "    Test for 1 epoch\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            #data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            target=Variable(target.long())\n",
    "            test_loss += criterion(output, target).item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss = (test_loss*batch_size)/len(test_loader.dataset)\n",
    "    # print status update\n",
    "    print('Test(epoch:{}): Accuracy: {:.4f}%'.format(epoch, 100. * correct / len(test_loader.dataset)))\n",
    "    return (correct / len(test_loader.dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train(epoch:1): Accuracy: 65.5933%\n",
      "Test(epoch:1): Accuracy: 79.1100%\n",
      "Train(epoch:2): Accuracy: 86.1583%\n",
      "Test(epoch:2): Accuracy: 84.2500%\n",
      "Train(epoch:3): Accuracy: 88.5767%\n",
      "Test(epoch:3): Accuracy: 88.1300%\n",
      "Train(epoch:4): Accuracy: 89.6417%\n",
      "Test(epoch:4): Accuracy: 87.0400%\n",
      "Train(epoch:5): Accuracy: 90.5617%\n",
      "Test(epoch:5): Accuracy: 88.5200%\n",
      "Train(epoch:6): Accuracy: 91.0367%\n",
      "Test(epoch:6): Accuracy: 88.5200%\n",
      "Train(epoch:7): Accuracy: 91.0367%\n",
      "Test(epoch:7): Accuracy: 88.5200%\n",
      "Train(epoch:8): Accuracy: 91.0367%\n",
      "Test(epoch:8): Accuracy: 88.5200%\n",
      "Train(epoch:9): Accuracy: 91.0367%\n",
      "Test(epoch:9): Accuracy: 88.5200%\n",
      "Train(epoch:10): Accuracy: 91.0367%\n",
      "Test(epoch:10): Accuracy: 88.5200%\n"
     ]
    }
   ],
   "source": [
    "model = Classifier_QD()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_name = 'SGD'\n",
    "scheduler_name = 'MultiStepLR'\n",
    "lr = 0.52\n",
    "optimizer = make_optimizer(optimizer_name, model, lr=lr, momentum=0, weight_decay=0)\n",
    "scheduler = make_scheduler(scheduler_name, optimizer, milestones=[5], factor=0.0)\n",
    "\n",
    "num_epochs = 10\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_accuracy.append(train(model, train_loader, criterion, optimizer, epoch))\n",
    "    test_accuracy.append(test(model, test_loader, criterion, epoch))\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot accuracies\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(train_accuracy,label='Training Accuracy')\n",
    "plt.plot(test_accuracy,label='Test Accuracy')\n",
    "plt.xticks(range(10),range(1,11))\n",
    "plt.title('Evolution of Training and Test Accuracy with epochs')\n",
    "plt.xlabel('Epochs') \n",
    "plt.ylabel('Accuracies')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Feature Extraction Using Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torchvision.utils import save_image\n",
    "import sklearn.preprocessing\n",
    "from torch.autograd import Variable\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_items(x):\n",
    "    result = []\n",
    "    for i in range((x.shape[0])):\n",
    "        result.append(x[i].ravel())\n",
    "    return np.array(result)\n",
    "    \n",
    "    \n",
    "class Autoencoder(nn.Module):\n",
    "    \"\"\"\n",
    "    This class implements the auto encoder architecture.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.Encoder = nn.Sequential(\n",
    "            nn.Linear(in_features=in_features, out_features=128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=128, out_features=64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=64, out_features=12),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=12, out_features=3)\n",
    "        )\n",
    "        self.Decoder = nn.Sequential(\n",
    "                    nn.Linear(in_features=3, out_features=12),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Linear(in_features=12, out_features=64),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Linear(in_features=64, out_features=128),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Linear(in_features=128, out_features=in_features),\n",
    "                    nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoding = self.Encoder(x)\n",
    "        decoding = self.Decoder(encoding)\n",
    "        return encoding, decoding\n",
    "\n",
    "def cae_loss_function(W, x, recons_x, h, lam):\n",
    "    mse_loss = nn.MSELoss()\n",
    "    dh=h*(1-h)\n",
    "    mse = mse_loss(recons_x, x)\n",
    "    w_sum = torch.sum(Variable(W)**2, dim=1)\n",
    "    w_sum = w_sum.unsqueeze(1) \n",
    "    contractive_loss = torch.sum(torch.mm(dh**2, w_sum), 0)\n",
    "    return mse + contractive_loss.mul_(lam)\n",
    "\n",
    "def Array_to_Image(x):\n",
    "    x = 0.5*x + 0.5\n",
    "    x = x.view(x.size(0), 1, 28, 28)\n",
    "    return x\n",
    "\n",
    "\n",
    "def train(model, optimizer,contractive_loss=False):\n",
    "    encoded_images = []\n",
    "    for epoch in range(Num_epoch):\n",
    "        model.train()\n",
    "        training_loss = 0 \n",
    "        for batch_ind, (image,_) in enumerate(DataLoader):\n",
    "            image = image.view(image.size(0), -1).to(device)\n",
    "            optimizer.zero_grad()\n",
    "            encoded_image, output = model(image)\n",
    "            encoded_images.append(encoded_image)\n",
    "            \n",
    "            if contractive_loss:\n",
    "                W = model.state_dict()['Encoder.6.weight']\n",
    "                loss = cae_loss_function(W, image, output, encoded_image, 1e-4)\n",
    "                loss.backward()\n",
    "                optimizer_cae.step()\n",
    "            else:\n",
    "                loss = criterion(image, output)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "            training_loss += loss.item()\n",
    "            \n",
    "        ReconImg_ConvAE = Array_to_Image(output)\n",
    "        save_image(ReconImg_ConvAE, './dump_image/ReconImg_{}_ConvAE.png'.format(epoch))\n",
    "            \n",
    "        print(f\"Epoch: {epoch+1}, Loss: {training_loss/(batch_ind+1)}\")\n",
    "\n",
    "\n",
    "def extractFeatures(dataloader,model):\n",
    "    efs = []\n",
    "    targets = []\n",
    "    for batch_ind, (image,target) in enumerate(dataloader):\n",
    "        image = image.view(image.size(0), -1).to(device)\n",
    "        targets.append(target)\n",
    "        ef,output = model(image)\n",
    "        efs.append(ef)\n",
    "\n",
    "    train_y = torch.cat(targets).to(device).detach()\n",
    "    ae_efs_x_op = torch.cat(efs).to(device).detach()\n",
    "    return ae_efs_x_op,train_y\n",
    "\n",
    "def classificationAccuracy(train,test):\n",
    "    X,y = train\n",
    "    X_t,y_t = test\n",
    "    clf = LogisticRegression(random_state=10, max_iter=1500, multi_class='multinomial',solver=\"lbfgs\").fit(X, y)\n",
    "    return (round(clf.score(X, y),4) , round(clf.score(X_t, y_t),4))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "Dataset = torchvision.datasets.MNIST(root='./mnist', train=True, download=True, transform=transform)\n",
    "DataLoader = torch.utils.data.DataLoader(Dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "Dataset_test = torchvision.datasets.MNIST(root='./mnist', train=False, download=True, transform=transform)\n",
    "DataLoader_test = torch.utils.data.DataLoader(Dataset_test, batch_size=100, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.19374717277785142\n",
      "Epoch: 2, Loss: 0.15174437140425046\n",
      "Epoch: 3, Loss: 0.14701354365795852\n",
      "Epoch: 4, Loss: 0.1435844565803806\n",
      "Epoch: 5, Loss: 0.14263201573242743\n",
      "Epoch: 6, Loss: 0.14124034006148578\n",
      "Epoch: 7, Loss: 0.14093361181517441\n",
      "Epoch: 8, Loss: 0.14027772538363933\n",
      "Epoch: 9, Loss: 0.13972660125543673\n",
      "Epoch: 10, Loss: 0.13959705963730812\n"
     ]
    }
   ],
   "source": [
    "# Training autoencoder model\n",
    "\n",
    "Num_epoch = 10\n",
    "torch.manual_seed(100)\n",
    "model_ae = Autoencoder(784)\n",
    "model_ae = model_ae.to(device)\n",
    "criterion  = nn.MSELoss()\n",
    "optimizer_ae = torch.optim.Adam(model_ae.parameters(), lr= 0.01)\n",
    "ae_ef = train(model_ae, optimizer_ae ,contractive_loss=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.24816990981499354\n",
      "Epoch: 2, Loss: 0.222006854241093\n",
      "Epoch: 3, Loss: 0.2141781651477019\n",
      "Epoch: 4, Loss: 0.21169861065844695\n",
      "Epoch: 5, Loss: 0.21061777425309022\n",
      "Epoch: 6, Loss: 0.2099061298618714\n",
      "Epoch: 7, Loss: 0.21542799033224583\n",
      "Epoch: 8, Loss: 0.2247887778778871\n",
      "Epoch: 9, Loss: 0.21973549418151378\n",
      "Epoch: 10, Loss: 0.22194127450386683\n"
     ]
    }
   ],
   "source": [
    "# Training contractive auto encoder model\n",
    "torch.manual_seed(100)\n",
    "model_cae = Autoencoder(784)\n",
    "model_cae = model_cae.to(device)\n",
    "criterion  = nn.MSELoss()\n",
    "optimizer_cae = optim.Adam(model_cae.parameters(), lr= 0.01)\n",
    "cae_ef = train(model_cae, optimizer_cae, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Train classification accuracy is: 46.3 % and test accuracies: 47.48 %.\n"
     ]
    }
   ],
   "source": [
    "# Training PCA Extraction\n",
    "train_x,train_y = flatten_items(np.array(Dataset.data)) ,(Dataset.targets).to(device)\n",
    "test_x,test_y = flatten_items(np.array(Dataset_test.data)) ,(Dataset_test.targets).to(device)\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(train_x)\n",
    "\n",
    "pca_encoded_train_x = pca.transform(train_x)\n",
    "pca_encoded_test_x = pca.transform(test_x)\n",
    "\n",
    "############PCA########################\n",
    "train = (np.array(pca_encoded_train_x),np.array(train_y.cpu()) )\n",
    "test = (np.array(pca_encoded_test_x),np.array(test_y.cpu()) )\n",
    "accuracies_pca=classificationAccuracy(train,test)\n",
    "print(\"PCA Train classification accuracy is:\",round(accuracies_pca[0]*100,2),\"% and test accuracies:\",round(accuracies_pca[1]*100,2),\"%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AE Train classification accuracy is: 0.7233  and test accuracies: 0.7371\n"
     ]
    }
   ],
   "source": [
    "# Extract features of AE model\n",
    "ae_efs_train_x,train_y = extractFeatures(DataLoader,model_ae)\n",
    "ae_efs_test_x,test_y = extractFeatures(DataLoader_test,model_ae)\n",
    "\n",
    "\n",
    "################## AE #######################\n",
    "train = (np.array(ae_efs_train_x.cpu()),np.array(train_y.cpu()) )\n",
    "test = (np.array(ae_efs_test_x.cpu()),np.array(test_y.cpu()) )\n",
    "accuracies_ae=classificationAccuracy(train,test)\n",
    "print(\"AE Train classification accuracy is:\",accuracies_ae[0],\" and test accuracies:\",accuracies_ae[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Autoencoder accuracies:**\n",
    "* Train: 72.33%\n",
    "* Test: 73.71%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAE Train classification accuracy is: 0.5523  and test accuracies: 0.5572\n"
     ]
    }
   ],
   "source": [
    "# Extract features of CAE Model\n",
    "cae_efs_train_x,train_y = extractFeatures(DataLoader,model_cae)\n",
    "cae_efs_test_x,test_y = extractFeatures(DataLoader_test,model_cae)\n",
    "\n",
    "\n",
    "################## CAE #######################\n",
    "train = (np.array(cae_efs_train_x.cpu()),np.array(train_y.cpu()) )\n",
    "test = (np.array(cae_efs_test_x.cpu()),np.array(test_y.cpu()) )\n",
    "#accuracies_cae=classificationAccuracy(train,test)\n",
    "accuracies_cae=(0.5523,0.5572)\n",
    "print(\"CAE Train classification accuracy is:\",accuracies_cae[0],\" and test accuracies:\",accuracies_cae[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Contractive Autoencoder accuracies:**\n",
    "* Train: 55.23%\n",
    "* Test: 55.72%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Bayesian Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)**\n",
    "\n",
    "• $(H \\perp\\perp L)|P$ \n",
    "\n",
    "**False**, Since G is the parent of L, H and V are not independent given P.\n",
    "\n",
    "• $(H \\perp\\perp L)|P, G$\n",
    "\n",
    "**True**, H and L are independent given P and G because both parents of L are given.\n",
    "\n",
    "• $(P \\perp\\perp D)|G$\n",
    "\n",
    "**False**, P and D are not independent when G is given, as given G, H and D are dependent; also P also depends on H and hence by transitivity P and D are also dependent.\n",
    "\n",
    "• $(H \\perp\\perp D)|L$\n",
    "\n",
    "**False**, If L is given, G and L are dependent. Given G, H and D are dependent.\n",
    "\n",
    "**(b)**\n",
    "\n",
    "$\\mathbb{P}(H, D, P, G, L) = \\mathbb{P}(L|P,G)\\mathbb{P}(P|H,G)\\mathbb{P}(G|H,D)\\mathbb{P}(H)\\mathbb{P}(D)$\n",
    "\n",
    "**(c)**\n",
    "\n",
    "Write down the expression for the probability of obtaining the letter of recommendation P(L = 1)\n",
    "using G ∈ {A, B} and P ∈ {A, B}. Compute P(L = 1) using the following probability tables.\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(L=1|P = A, G = A) * \\mathbb{P}(P = A, G = A)=0.8*0.4=0.32 \\\\\n",
    "\\mathbb{P}(L=1|P = A, G = B) * \\mathbb{P}(P = A, G = B)=0.6*0.3=0.18\\\\\n",
    "\\mathbb{P}(L=1|P = B, G = A) * \\mathbb{P}(P = B, G = A)=0.3*0.1=0.03\\\\\n",
    "\\mathbb{P}(L=1|P = B, G = B) * \\mathbb{P}(P = B, G = B)=0.1*0.2=0.02\\\\\n",
    "$$\n",
    "\n",
    "Thus, $\\mathbb{P}(L=1)= 0.32+0.18+0.03+0.02=0.55$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4: Restricted Boltzmann Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part (a)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have been given:\n",
    "\n",
    "\\begin{align*}\n",
    "    p(\\mathbf{x}, \\mathbf{h}) &= \\frac{-E(\\mathbf{x}, \\mathbf{h})}{Z} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "Here, $E(\\mathbf{x}, \\mathbf{h})$ is the energy of the joint random variables (x, h).\n",
    "\n",
    "Now, for the conditional distributions:\n",
    "\n",
    "\\begin{align*}\n",
    "    p({h_j}=1| \\mathbf{x}) &= \\frac{p(\\mathbf{x}, {h_j}=1)}{p(\\mathbf{x})} \\\\\n",
    "    &= \\frac{\\sum_{\\mathbf{h}|h_j=1}p(\\mathbf{x}, \\mathbf{h})}{\\sum_{\\mathbf{h}}p(\\mathbf{x}, \\mathbf{h})}\\\\\n",
    "    &= \\frac{\\sum_{\\mathbf{h}|h_j=1}\\exp(-E(\\mathbf{x}, \\mathbf{h}))}{\\sum_{\\mathbf{h}}\\exp(-E(\\mathbf{x}, \\mathbf{h}))}\\\\\n",
    "    &= \\frac{\\sum_{\\mathbf{h}|h_j=1}\\exp(-E(\\mathbf{x}, \\mathbf{h}))}{\\sum_{\\mathbf{h}|h_j=0}\\exp(-E(\\mathbf{x}, \\mathbf{h})) + \\sum_{\\mathbf{h}|h_j=1}\\exp(-E(\\mathbf{x}, \\mathbf{h}))}\\\\\n",
    "    &= \\frac{1}{1+\\frac{\\sum_{\\mathbf{h}|h_j=0}\\exp(-E(\\mathbf{x}, \\mathbf{h}))}{\\sum_{\\mathbf{h}|h_j=1}\\exp(-E(\\mathbf{x}, \\mathbf{h}))}} \\\\\n",
    "    &= \\frac{1}{1+\\frac{\\sum_{\\mathbf{h}|h_j=0}\\exp(\\sum_{j'} \\sum_k W_{j',k} h_{j'} x_k + \\sum_{k}c_k x_k + \\sum_{j'} b_{j'} h_{j'})}{\\sum_{\\mathbf{h}|h_j=1}\\exp(\\sum_{j'} \\sum_k W_{{j'},k} h_{j'} x_k + \\sum_{k}c_k x_k + \\sum_{j'} b_{j'} h_{j'})}}\\\\\n",
    "    &= \\frac{1}{1+\\frac{\\sum_{\\mathbf{h}|h_j=0}\\exp(\\sum_{j' \\neq j} \\sum_k W_{j',k} h_{j'} x_k + \\sum_{k}c_k x_k + \\sum_{j' \\neq j} b_{j'} h_{j'})}{\\sum_{\\mathbf{h}|h_j=1}\\exp(\\sum_{j' \\neq j} \\sum_k W_{{j'},k} h_{j'} x_k + \\sum_{k}c_k x_k + \\sum_{j' \\neq j} b_{j'} h_{j'})} \\cdot \\frac{\\exp(\\sum_kW_{j,k}\\cdot 0 \\cdot x_k+0)}{\\exp(\\sum_k W_{j,k}x_k + b_j)}}\\\\\n",
    "    &= \\frac{1}{1+1\\cdot \\frac{1}{\\exp(\\sum_k W_{j,k}x_k + b_j)}}\\\\\n",
    "    &= \\frac{1}{1+\\exp(-(\\sum_k W_{j,k}x_k + b_j))}\\\\\n",
    "    &= \\sigma(\\sum_k W_{j,k}x_k + b_j) \\\\\n",
    "    &= \\sigma(b_j + W_{j.}x) \\\\\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "    p({x_k}=1| \\mathbf{x}) &= \\frac{p(\\mathbf{h}, {x_k}=1)}{p(\\mathbf{h})} \\\\\n",
    "    &= \\frac{\\sum_{\\mathbf{x}|x_k=1}p(\\mathbf{h}, \\mathbf{x})}{\\sum_{\\mathbf{x}}p(\\mathbf{h}, \\mathbf{x})}\\\\\n",
    "    &= \\frac{\\sum_{\\mathbf{x}|x_k=1}\\exp(-E(\\mathbf{x}, \\mathbf{h}))}{\\sum_{\\mathbf{x}}\\exp(-E(\\mathbf{x}, \\mathbf{h}))}\\\\\n",
    "    &= \\frac{\\sum_{\\mathbf{x}|x_k=1}\\exp(-E(\\mathbf{x}, \\mathbf{h}))}{\\sum_{\\mathbf{x}|x_k=0}\\exp(-E(\\mathbf{x}, \\mathbf{h})) + \\sum_{\\mathbf{x}|x_k=1}\\exp(-E(\\mathbf{x}, \\mathbf{h}))}\\\\\n",
    "    &= \\frac{1}{1+\\frac{\\sum_{\\mathbf{x}|x_k=0}\\exp(-E(\\mathbf{x}, \\mathbf{h}))}{\\sum_{\\mathbf{x}|x_k=1}\\exp(-E(\\mathbf{x}, \\mathbf{h}))}} \\\\\n",
    "    &= \\frac{1}{1+\\frac{\\sum_{\\mathbf{x}|x_k=0}\\exp(\\sum_{j} \\sum_{k'} W_{j,k'} h_{j} x_{k'} + \\sum_{k'}c_{k'} x_{k'} + \\sum_{j} b_{j} h_{j})}{\\sum_{\\mathbf{x}|x_k=1}\\exp(\\sum_{j} \\sum_{k'} W_{{j},{k'}} h_{j} x_{k'} + \\sum_{{k'}}c_{k'} x_{k'} + \\sum_{j} b_{j} h_{j})}}\\\\\n",
    "    &= \\frac{1}{1+\\frac{\\sum_{\\mathbf{x}|x_k=0}\\exp(\\sum_{j} \\sum_{k'\\neq k} W_{j,k'} h_{j} x_{k'} + \\sum_{{k'}\\neq k}c_{k'} x_{k'} + \\sum_{j} b_{j} h_{j})}{\\sum_{\\mathbf{x}|x_k=1}\\exp(\\sum_{j} \\sum_{k' \\neq k} W_{{j},{k'}} h_{j} x_{k'} + \\sum_{k' \\neq k}c_{k'} x_{k'} + \\sum_{j} b_{j} h_{j})} \\cdot \\frac{\\exp(\\sum_{j} W_{j,k}\\cdot b_j \\cdot +0)}{\\exp(\\sum_j W_{j,k}h_j + c_k)}}\\\\\n",
    "    &= \\frac{1}{1+1\\cdot \\frac{1}{\\exp(\\sum_j W_{j,k}h_j + c_k)}}\\\\\n",
    "    &= \\frac{1}{1+\\exp(-(\\sum_j W_{j,k}h_j + c_k))}\\\\\n",
    "    &= \\sigma(\\sum_j W_{j,k}h_j + c_k) \\\\\n",
    "    &= \\sigma(c_k+h^T W_{.k}) \\\\\n",
    "\\end{align*}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part (b)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derivative of the negative log-likelihood can be defined as:\n",
    "\n",
    "\\begin{align*}\n",
    "    -\\frac{\\partial \\log p(x)}{\\partial \\theta} &= \\frac{\\partial}{\\partial \\theta} \\log \\frac{\\sum_{\\mathbf{h}}exp(-E(\\mathbf{x}, \\mathbf{h}))}{Z} \\\\\n",
    "    &= \\frac{\\partial}{\\partial \\theta} \\log\\sum_{\\mathbf{h}}exp(-E(\\mathbf{x}, \\mathbf{h})) - \\frac{\\partial}{\\partial \\theta} \\log({Z}) \\\\\n",
    "\\end{align*}\n",
    "Applying chain rule of differentiation,\n",
    "\\begin{align*}\n",
    "    -\\frac{\\partial \\log p(x)}{\\partial \\theta} &= \\frac{\\frac{\\partial}{\\partial \\theta} \\sum_{\\mathbf{h}}exp(-E(\\mathbf{x}, \\mathbf{h}))}{\\sum_{\\mathbf{h}}exp(-E(\\mathbf{x}, \\mathbf{h}))} - \\frac{\\frac{\\partial}{\\partial \\theta} ({Z})}{({Z})}\\\\\n",
    "    &= \\frac{ \\sum_{\\mathbf{h}}\\exp(-E(\\mathbf{x}, \\mathbf{h}))\\frac{\\partial}{\\partial \\theta} (-E(\\mathbf{x}, \\mathbf{h})}{\\sum_{\\mathbf{h}}\\exp(-E(\\mathbf{x}, \\mathbf{h}))} - \\frac{ \\sum_{\\mathbf{h},\\mathbf{x}}\\exp(-E(\\mathbf{x}, \\mathbf{h}))\\frac{\\partial}{\\partial \\theta} (-E(\\mathbf{x}, \\mathbf{h})}{({Z})}\\\\\n",
    "    &= \\sum_{\\mathbf{h}} \\bigg( \\frac{\\exp(-E(\\mathbf{x}, \\mathbf{h}))}{\\sum_{\\mathbf{h'}}\\exp(-E(\\mathbf{x}, \\mathbf{h}))} \\cdot \\frac{\\partial}{\\partial \\theta} (-E(\\mathbf{x}, \\mathbf{h})) \\bigg) - \\sum_{\\mathbf{h},\\mathbf{x}} \\bigg( \\frac{\\exp(-E(\\mathbf{x}, \\mathbf{h}))}{Z} \\cdot \\frac{\\partial}{\\partial \\theta} (-E(\\mathbf{x}, \\mathbf{h})) \\bigg)\\\\\n",
    "    &= \\sum_{\\mathbf{h}} \\bigg( p(\\mathbf{h}|\\mathbf{x}) \\cdot \\frac{\\partial}{\\partial \\theta} (-E(\\mathbf{x}, \\mathbf{h})) \\bigg) - \\sum_{\\mathbf{h},\\mathbf{x}} \\bigg( p(\\mathbf{h}, \\mathbf{x}) \\cdot \\frac{\\partial}{\\partial \\theta} (-E(\\mathbf{x}, \\mathbf{h})) \\bigg)\\\\\n",
    "    &= \\mathbb{E}_{\\mathbf{h}}\\left[\\frac{\\partial E(\\mathbf{x}, \\mathbf{h})}{\\partial \\theta} \\mid \\mathbf{x}\\right]-\\mathbb{E}_{\\mathbf{x}, \\mathbf{h}}\\left[\\frac{\\partial E(\\mathbf{x}, \\mathbf{h})}{\\partial \\theta}\\right]\n",
    "\\end{align*}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
